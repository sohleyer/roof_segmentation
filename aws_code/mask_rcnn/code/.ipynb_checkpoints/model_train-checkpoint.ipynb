{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Training Model\n",
    "\n",
    "<i> SÃ©bastien Ohleyer </i>\n",
    "\n",
    "Training notebook.\n",
    "\n",
    "Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline\n",
    "ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.85\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (128, 128)\n",
      "NAME                           aerial\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.8\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                180\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               40\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aerial\n",
    "config = aerial.AerialConfig()\n",
    "\n",
    "# Local\n",
    "#AERIAL_DIR = \"/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/AerialImageDataset/\"  # TODO: enter value here\n",
    "#COCO_MODEL_PATH = \"~/Document/ENS MVA/Object recognition/Mask_RCNN-coco/coco_weigths/mask_rcnn_coco.h5\"\n",
    "#MODEL_DIR = \"../trained_model/\"\n",
    "\n",
    "# Floydhub\n",
    "#AERIAL_DIR = \"/\"  # TODO: enter value here\n",
    "#COCO_MODEL_PATH = \"/coco_weights/mask_rcnn_aerial_0035.h5\"\n",
    "#MODEL_DIR = \"/output/trained_model/\"\n",
    "# run : floyd run --data sohleyer/datasets/aerialimagedataset_train/1:/train --data sohleyer/datasets/coco_weights/1:/coco_weights --env tensorflow-1.3 --mode jupyter\n",
    "\n",
    "# AWS\n",
    "AERIAL_DIR = \"/home/ubuntu/aerialimagedataset\"  # TODO: enter value here\n",
    "COCO_MODEL_PATH = \"/home/ubuntu/mask_rcnn/trained_model/11_mask_rcnn_aerial_0010.h5\"\n",
    "MODEL_DIR = \"/home/ubuntu/mask_rcnn/output/\"\n",
    "# run : floyd run --data sohleyer/datasets/aerialimagedataset_train/1:/train --data sohleyer/datasets/coco_weights/1:/coco_weights --env tensorflow-1.3 --mode jupyter\n",
    "\n",
    "TOWN_LIST = [\"austin\", \"chicago\", \"kitsap\", \"tyrol-w\", \"vienna\"]\n",
    "IMAGE_PER_TOWN = None\n",
    "SUBIMAGE_LIST = [(2,3), (3,2)]\n",
    "\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Count: 360\n",
      "Class Info: [{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'aerial', 'id': 1, 'name': 'building'}]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset train\n",
    "dataset_train = aerial.AerialDataset()\n",
    "dataset_train.load_aerial(dataset_dir=AERIAL_DIR, subset=\"train\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST, image_per_town=IMAGE_PER_TOWN)\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset_train.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[dataset_train.image_info[i][\"image_name\"] for i in dataset_train.image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Count: 310\n",
      "Class Info: [{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'aerial', 'id': 1, 'name': 'building'}]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset val\n",
    "dataset_val = aerial.AerialDataset()\n",
    "dataset_val.load_aerial(dataset_dir=AERIAL_DIR, subset=\"val\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST, image_per_town=IMAGE_PER_TOWN)\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset_val.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[dataset_val.image_info[i][\"image_name\"] for i in dataset_val.image_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/mask_rcnn/trained_model/11_mask_rcnn_aerial_0010.h5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 : Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.00025\n",
      "\n",
      "Checkpoint Path: /home/ubuntu/mask_rcnn/output/aerial20180116T1815/mask_rcnn_aerial_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/10\n",
      " 11/180 [>.............................] - ETA: 13:47 - loss: 1.5521 - rpn_class_loss: 0.1179 - rpn_bbox_loss: 0.5964 - mrcnn_class_loss: 0.2658 - mrcnn_bbox_loss: 0.2322 - mrcnn_mask_loss: 0.3398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/imageio/plugins/_tifffile.py:4513: UserWarning: unexpected end of lzw stream (code 514)\n",
      "  warnings.warn(\"unexpected end of lzw stream (code %i)\" % code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/180 [====>.........................] - ETA: 10:13 - loss: 1.6438 - rpn_class_loss: 0.1298 - rpn_bbox_loss: 0.5937 - mrcnn_class_loss: 0.2988 - mrcnn_bbox_loss: 0.2585 - mrcnn_mask_loss: 0.3629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/imageio/plugins/_tifffile.py:4513: UserWarning: unexpected end of lzw stream (code 514)\n",
      "  warnings.warn(\"unexpected end of lzw stream (code %i)\" % code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 796s 4s/step - loss: 1.5317 - rpn_class_loss: 0.1170 - rpn_bbox_loss: 0.5275 - mrcnn_class_loss: 0.3024 - mrcnn_bbox_loss: 0.2394 - mrcnn_mask_loss: 0.3455 - val_loss: 0.9806 - val_rpn_class_loss: 0.0727 - val_rpn_bbox_loss: 0.1990 - val_mrcnn_class_loss: 0.2347 - val_mrcnn_bbox_loss: 0.1710 - val_mrcnn_mask_loss: 0.3032\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 789s 4s/step - loss: 1.3665 - rpn_class_loss: 0.0969 - rpn_bbox_loss: 0.4106 - mrcnn_class_loss: 0.3025 - mrcnn_bbox_loss: 0.2214 - mrcnn_mask_loss: 0.3350 - val_loss: 0.9230 - val_rpn_class_loss: 0.0687 - val_rpn_bbox_loss: 0.1807 - val_mrcnn_class_loss: 0.2063 - val_mrcnn_bbox_loss: 0.1811 - val_mrcnn_mask_loss: 0.2861\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 757s 4s/step - loss: 1.3956 - rpn_class_loss: 0.0993 - rpn_bbox_loss: 0.4429 - mrcnn_class_loss: 0.2998 - mrcnn_bbox_loss: 0.2187 - mrcnn_mask_loss: 0.3349 - val_loss: 0.9400 - val_rpn_class_loss: 0.0695 - val_rpn_bbox_loss: 0.1997 - val_mrcnn_class_loss: 0.2237 - val_mrcnn_bbox_loss: 0.1606 - val_mrcnn_mask_loss: 0.2865\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 786s 4s/step - loss: 1.4308 - rpn_class_loss: 0.1038 - rpn_bbox_loss: 0.4904 - mrcnn_class_loss: 0.2959 - mrcnn_bbox_loss: 0.2109 - mrcnn_mask_loss: 0.3297 - val_loss: 0.8390 - val_rpn_class_loss: 0.0667 - val_rpn_bbox_loss: 0.1778 - val_mrcnn_class_loss: 0.1926 - val_mrcnn_bbox_loss: 0.1374 - val_mrcnn_mask_loss: 0.2645\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 785s 4s/step - loss: 1.3224 - rpn_class_loss: 0.0931 - rpn_bbox_loss: 0.3996 - mrcnn_class_loss: 0.2906 - mrcnn_bbox_loss: 0.2068 - mrcnn_mask_loss: 0.3322 - val_loss: 0.7861 - val_rpn_class_loss: 0.0641 - val_rpn_bbox_loss: 0.1616 - val_mrcnn_class_loss: 0.1752 - val_mrcnn_bbox_loss: 0.1286 - val_mrcnn_mask_loss: 0.2566\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 754s 4s/step - loss: 1.2692 - rpn_class_loss: 0.0909 - rpn_bbox_loss: 0.3586 - mrcnn_class_loss: 0.2836 - mrcnn_bbox_loss: 0.2043 - mrcnn_mask_loss: 0.3317 - val_loss: 0.7452 - val_rpn_class_loss: 0.0657 - val_rpn_bbox_loss: 0.1781 - val_mrcnn_class_loss: 0.1525 - val_mrcnn_bbox_loss: 0.1121 - val_mrcnn_mask_loss: 0.2369\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 754s 4s/step - loss: 1.3143 - rpn_class_loss: 0.0888 - rpn_bbox_loss: 0.4545 - mrcnn_class_loss: 0.2646 - mrcnn_bbox_loss: 0.1903 - mrcnn_mask_loss: 0.3162 - val_loss: 0.8149 - val_rpn_class_loss: 0.0634 - val_rpn_bbox_loss: 0.1899 - val_mrcnn_class_loss: 0.1922 - val_mrcnn_bbox_loss: 0.1343 - val_mrcnn_mask_loss: 0.2351\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 782s 4s/step - loss: 1.2662 - rpn_class_loss: 0.0919 - rpn_bbox_loss: 0.3763 - mrcnn_class_loss: 0.2766 - mrcnn_bbox_loss: 0.1921 - mrcnn_mask_loss: 0.3293 - val_loss: 0.7614 - val_rpn_class_loss: 0.0582 - val_rpn_bbox_loss: 0.1500 - val_mrcnn_class_loss: 0.1756 - val_mrcnn_bbox_loss: 0.1524 - val_mrcnn_mask_loss: 0.2252\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 763s 4s/step - loss: 1.2267 - rpn_class_loss: 0.0876 - rpn_bbox_loss: 0.3601 - mrcnn_class_loss: 0.2724 - mrcnn_bbox_loss: 0.1857 - mrcnn_mask_loss: 0.3210 - val_loss: 0.7144 - val_rpn_class_loss: 0.0530 - val_rpn_bbox_loss: 0.1401 - val_mrcnn_class_loss: 0.1988 - val_mrcnn_bbox_loss: 0.0993 - val_mrcnn_mask_loss: 0.2232\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 838s 5s/step - loss: 1.1869 - rpn_class_loss: 0.0848 - rpn_bbox_loss: 0.3181 - mrcnn_class_loss: 0.2755 - mrcnn_bbox_loss: 0.1819 - mrcnn_mask_loss: 0.3267 - val_loss: 0.6005 - val_rpn_class_loss: 0.0440 - val_rpn_bbox_loss: 0.1190 - val_mrcnn_class_loss: 0.1343 - val_mrcnn_bbox_loss: 0.0942 - val_mrcnn_mask_loss: 0.2090\n"
     ]
    }
   ],
   "source": [
    "# Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE/4, epochs=10, layers='4+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 10. LR=5e-05\n",
      "\n",
      "Checkpoint Path: /home/ubuntu/mask_rcnn/output/aerial20180118T1557/mask_rcnn_aerial_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "  3/180 [..............................] - ETA: 20:15 - loss: 1.7864 - rpn_class_loss: 0.0947 - rpn_bbox_loss: 0.9788 - mrcnn_class_loss: 0.2094 - mrcnn_bbox_loss: 0.1641 - mrcnn_mask_loss: 0.3394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/imageio/plugins/_tifffile.py:4513: UserWarning: unexpected end of lzw stream (code 514)\n",
      "  warnings.warn(\"unexpected end of lzw stream (code %i)\" % code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/180 [=>............................] - ETA: 13:53 - loss: 1.4600 - rpn_class_loss: 0.1018 - rpn_bbox_loss: 0.5479 - mrcnn_class_loss: 0.3048 - mrcnn_bbox_loss: 0.1827 - mrcnn_mask_loss: 0.3228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.6/site-packages/imageio/plugins/_tifffile.py:4513: UserWarning: unexpected end of lzw stream (code 514)\n",
      "  warnings.warn(\"unexpected end of lzw stream (code %i)\" % code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 804s 4s/step - loss: 1.2103 - rpn_class_loss: 0.0808 - rpn_bbox_loss: 0.3740 - mrcnn_class_loss: 0.2865 - mrcnn_bbox_loss: 0.1599 - mrcnn_mask_loss: 0.3091 - val_loss: 0.7821 - val_rpn_class_loss: 0.0928 - val_rpn_bbox_loss: 0.1051 - val_mrcnn_class_loss: 0.1618 - val_mrcnn_bbox_loss: 0.1331 - val_mrcnn_mask_loss: 0.2893\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 768s 4s/step - loss: 1.1276 - rpn_class_loss: 0.0764 - rpn_bbox_loss: 0.2998 - mrcnn_class_loss: 0.2795 - mrcnn_bbox_loss: 0.1603 - mrcnn_mask_loss: 0.3116 - val_loss: 0.7823 - val_rpn_class_loss: 0.0899 - val_rpn_bbox_loss: 0.1013 - val_mrcnn_class_loss: 0.1568 - val_mrcnn_bbox_loss: 0.1443 - val_mrcnn_mask_loss: 0.2902\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 770s 4s/step - loss: 1.1572 - rpn_class_loss: 0.0764 - rpn_bbox_loss: 0.3538 - mrcnn_class_loss: 0.2747 - mrcnn_bbox_loss: 0.1480 - mrcnn_mask_loss: 0.3042 - val_loss: 0.7858 - val_rpn_class_loss: 0.0891 - val_rpn_bbox_loss: 0.1028 - val_mrcnn_class_loss: 0.1690 - val_mrcnn_bbox_loss: 0.1256 - val_mrcnn_mask_loss: 0.2993\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 768s 4s/step - loss: 1.1229 - rpn_class_loss: 0.0748 - rpn_bbox_loss: 0.2968 - mrcnn_class_loss: 0.2822 - mrcnn_bbox_loss: 0.1580 - mrcnn_mask_loss: 0.3112 - val_loss: 0.8132 - val_rpn_class_loss: 0.0906 - val_rpn_bbox_loss: 0.1031 - val_mrcnn_class_loss: 0.1872 - val_mrcnn_bbox_loss: 0.1324 - val_mrcnn_mask_loss: 0.2999\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 790s 4s/step - loss: 1.1306 - rpn_class_loss: 0.0764 - rpn_bbox_loss: 0.3281 - mrcnn_class_loss: 0.2731 - mrcnn_bbox_loss: 0.1463 - mrcnn_mask_loss: 0.3067 - val_loss: 0.7680 - val_rpn_class_loss: 0.0873 - val_rpn_bbox_loss: 0.0976 - val_mrcnn_class_loss: 0.1517 - val_mrcnn_bbox_loss: 0.1321 - val_mrcnn_mask_loss: 0.2993\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 787s 4s/step - loss: 1.1800 - rpn_class_loss: 0.0816 - rpn_bbox_loss: 0.3418 - mrcnn_class_loss: 0.2867 - mrcnn_bbox_loss: 0.1596 - mrcnn_mask_loss: 0.3103 - val_loss: 0.7539 - val_rpn_class_loss: 0.0882 - val_rpn_bbox_loss: 0.0976 - val_mrcnn_class_loss: 0.1557 - val_mrcnn_bbox_loss: 0.1288 - val_mrcnn_mask_loss: 0.2837\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 754s 4s/step - loss: 1.1227 - rpn_class_loss: 0.0763 - rpn_bbox_loss: 0.3150 - mrcnn_class_loss: 0.2721 - mrcnn_bbox_loss: 0.1522 - mrcnn_mask_loss: 0.3072 - val_loss: 0.7940 - val_rpn_class_loss: 0.0875 - val_rpn_bbox_loss: 0.1013 - val_mrcnn_class_loss: 0.1873 - val_mrcnn_bbox_loss: 0.1247 - val_mrcnn_mask_loss: 0.2932\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 824s 5s/step - loss: 1.1254 - rpn_class_loss: 0.0809 - rpn_bbox_loss: 0.3010 - mrcnn_class_loss: 0.2882 - mrcnn_bbox_loss: 0.1539 - mrcnn_mask_loss: 0.3014 - val_loss: 0.7283 - val_rpn_class_loss: 0.0864 - val_rpn_bbox_loss: 0.0971 - val_mrcnn_class_loss: 0.1418 - val_mrcnn_bbox_loss: 0.1215 - val_mrcnn_mask_loss: 0.2814\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 756s 4s/step - loss: 1.0684 - rpn_class_loss: 0.0724 - rpn_bbox_loss: 0.2763 - mrcnn_class_loss: 0.2688 - mrcnn_bbox_loss: 0.1499 - mrcnn_mask_loss: 0.3009 - val_loss: 0.7443 - val_rpn_class_loss: 0.0839 - val_rpn_bbox_loss: 0.0958 - val_mrcnn_class_loss: 0.1587 - val_mrcnn_bbox_loss: 0.1204 - val_mrcnn_mask_loss: 0.2856\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 771s 4s/step - loss: 1.1729 - rpn_class_loss: 0.0755 - rpn_bbox_loss: 0.3685 - mrcnn_class_loss: 0.2698 - mrcnn_bbox_loss: 0.1515 - mrcnn_mask_loss: 0.3075 - val_loss: 0.7493 - val_rpn_class_loss: 0.0864 - val_rpn_bbox_loss: 0.0958 - val_mrcnn_class_loss: 0.1630 - val_mrcnn_bbox_loss: 0.1158 - val_mrcnn_mask_loss: 0.2882\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 : Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE / 20, epochs=20, layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
