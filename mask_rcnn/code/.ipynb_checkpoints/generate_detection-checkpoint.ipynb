{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Generate detections on Inria Aerial Dataset\n",
    "\n",
    "<i> SÃ©bastien Ohleyer </i>\n",
    "\n",
    "Generates detections on the Inria Aerial Dataset for submissions.\n",
    "\n",
    "Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/objreco_namr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/sebastienohleyer/anaconda3/envs/objreco_namr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from model import log\n",
    "\n",
    "from PIL import Image\n",
    "import csv\n",
    "from compute_stats import compute_iou,compute_accuracy\n",
    "import imageio\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\") #Local\n",
    "#MODEL_DIR = \"/output/trained_model/\"#Floydhub\n",
    "#MODEL_DIR = \"/home/ubuntu/mask_rcnn/output/\" #AWS\n",
    "\n",
    "# Directory of Aerial dataset\n",
    "AERIAL_DIR = \"/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/AerialImageDataset/\" #Local\n",
    "#AERIAL_DIR = \"/\" #Floydhub\n",
    "#AERIAL_DIR = \"/home/ubuntu/aerialimagedataset/\"  #AWS\n",
    "\n",
    "# Directory of Aerial model\n",
    "WEIGHTS_PATH = \"/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/mask_rcnn/trained_model/11_mask_rcnn_aerial_0010.h5\" #Local\n",
    "#WEIGHTS_PATH = \"/coco_weights/11_mask_rcnn_aerial_0010.h5\" #Floydhub\n",
    "#WEIGHTS_PATH = \"/home/ubuntu/mask_rcnn/trained_model/11_mask_rcnn_aerial_0010.h5\" #AWS\n",
    "\n",
    "# Directory for results\n",
    "PREDICTIONS_DIR = \"/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/mask_rcnn/predictions/\" #Local\n",
    "#PREDICTIONS_DIR = \"/output/code/\" #Floydhub\n",
    "#PREDICTIONS_DIR = \"/home/ubuntu/mask_rcnn/predictions/\" #AWS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 123.7  116.8  103.9]\n",
      "MINI_MASK_SHAPE                (128, 128)\n",
      "NAME                           aerial\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                90\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               20\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aerial\n",
    "config = aerial.AerialConfig()\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOWN_LIST = [\"austin\",\"chicago\",\"tyrol-w\",\"kitsap\",\"vienna\"]\n",
    "\n",
    "SUBIMAGE_LIST=[]\n",
    "for i in range(5):\n",
    "    SUBIMAGE_LIST = SUBIMAGE_LIST + [(i,j) for j in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SUBIMAGE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Count: 4500\n",
      "Class Info: [{'source': '', 'id': 0, 'name': 'BG'}, {'source': 'aerial', 'id': 1, 'name': 'building'}]\n"
     ]
    }
   ],
   "source": [
    "dataset = aerial.AerialDataset()\n",
    "dataset.load_aerial(dataset_dir=AERIAL_DIR, subset=\"train\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST)\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height': 1024,\n",
       " 'id': 101,\n",
       " 'image_name': 'austin1_01.tif',\n",
       " 'mask_path': '/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/AerialImageDataset/train/gt/austin1.tif',\n",
       " 'path': '/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/AerialImageDataset/train/images/austin1.tif',\n",
       " 'source': 'aerial',\n",
       " 'subimage': (0, 1),\n",
       " 'width': 1024}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_info[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /Users/sebastienohleyer/Documents/ENS MVA/Object recognition/mask_rcnn/trained_model/11_mask_rcnn_aerial_0010.h5\n"
     ]
    }
   ],
   "source": [
    "# Create model in inference mode\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "weights_path = WEIGHTS_PATH\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_idx(image_info,image_name):\n",
    "    for i, image in enumerate(image_info):\n",
    "        if image[\"image_name\"] == image_name:\n",
    "            return i\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, name in enumerate(dataset.image_names[9:]):\n",
    "    print(name)\n",
    "    mask_gt_concatenate=np.zeros((5000,5000))\n",
    "    mask_maskrcnn_concatenate=np.zeros((5000,5000))\n",
    "    \n",
    "    gt = imageio.imread(AERIAL_DIR+\"train/gt/\"+name)\n",
    "    gt = np.where(gt==255,1,0)\n",
    "    \n",
    "    for subimage in SUBIMAGE_LIST:\n",
    "        image_name_split = name.split(\".\")\n",
    "        new_name = \".\".join([image_name_split[0]+'_'+str(subimage[0])+str(subimage[1]), image_name_split[1]])\n",
    "        image_idx = find_idx(dataset.image_info,new_name)\n",
    "        \n",
    "        # Ground truth\n",
    "        mask_gt,_ = dataset.load_mask(image_idx)\n",
    "        full_mask_gt = np.sum(mask_gt,2)\n",
    "        \n",
    "        image, _, _, _, _ = modellib.load_image_gt(dataset, config, image_idx, use_mini_mask=False)\n",
    "    \n",
    "        # Prediction\n",
    "        print(\"Start prediction\", subimage)\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        if len(r['class_ids']) == 0: #no instance detected\n",
    "            full_mask_maskrcnn = np.zeros((1024,1024))\n",
    "        else:\n",
    "            mask_rcnn = r[\"masks\"]\n",
    "            full_mask_maskrcnn = np.sum(mask_rcnn,2)\n",
    "            full_mask_maskrcnn = np.where(full_mask_maskrcnn<2,full_mask_maskrcnn,1)\n",
    "        \n",
    "        (subimx,subimy) = subimage\n",
    "        if subimx<4 and subimy<4:\n",
    "            mask_gt_concatenate[subimy*1024:(subimy+1)*1024, subimx*1024:(subimx+1)*1024]=full_mask_gt\n",
    "            mask_maskrcnn_concatenate[subimy*1024:(subimy+1)*1024, subimx*1024:(subimx+1)*1024]=full_mask_maskrcnn\n",
    "        \n",
    "        elif subimx==4 and subimy!=4:\n",
    "            mask_gt_concatenate[subimy*1024:(subimy+1)*1024, 3976:5000]=full_mask_gt\n",
    "            mask_maskrcnn_concatenate[subimy*1024:(subimy+1)*1024, 3976:5000]=full_mask_maskrcnn\n",
    "            \n",
    "        elif subimy==4 and subimx!=4:\n",
    "            mask_gt_concatenate[3976:5000, subimx*1024:(subimx+1)*1024]=full_mask_gt\n",
    "            mask_maskrcnn_concatenate[3976:5000, subimx*1024:(subimx+1)*1024]=full_mask_maskrcnn\n",
    "            \n",
    "        elif subimy==4 and subimx==4:\n",
    "            mask_gt_concatenate[3976:5000, 3976:5000]=full_mask_gt\n",
    "            mask_maskrcnn_concatenate[3976:5000, 3976:5000]=full_mask_maskrcnn\n",
    "            \n",
    "    mask_gt_concatenate = mask_gt_concatenate.astype(np.uint8)\n",
    "    mask_maskrcnn_concatenate = mask_maskrcnn_concatenate.astype(np.uint8)\n",
    "            \n",
    "    image_result = [compute_accuracy(gt, mask_gt_concatenate), compute_iou(gt,mask_gt_concatenate),\n",
    "                        compute_accuracy(gt,mask_maskrcnn_concatenate), compute_iou(gt,mask_maskrcnn_concatenate)]\n",
    "    print(image_result)\n",
    "    results.append(image_result)\n",
    "        \n",
    "    print(\"Image saved !\")\n",
    "    out = Image.fromarray((mask_maskrcnn_concatenate*255).astype(np.uint8))\n",
    "    out.save(PREDICTIONS_DIR+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows([[\"image_name\", \"gt_concat_acc\", \"gt_concat_iou\", \"maskrcnn_acc\", \"mask_rcnn_iou\"]]+results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOWN_LIST_TEST = [\"bellingham\", \"bloomington\", \"innsbruck\", \"sfo\", \"tyrol-e\"]\n",
    "\n",
    "dataset_test = aerial.AerialDataset()\n",
    "dataset_test.load_aerial(dataset_dir=AERIAL_DIR, subset=\"test\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST_TEST)\n",
    "dataset_test.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_test.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset_test.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, name in enumerate(dataset.image_names):\n",
    "    print(name)\n",
    "    mask_maskrcnn_concatenate=np.zeros((5000,5000))\n",
    "    \n",
    "    for subimage in SUBIMAGE_LIST:\n",
    "        image_name_split = name.split(\".\")\n",
    "        new_name = \".\".join([image_name_split[0]+'_'+str(subimage[0])+str(subimage[1]), image_name_split[1]])\n",
    "        image_idx = find_idx(dataset.image_info,new_name)\n",
    "        \n",
    "        image, _, _, _, _ = modellib.load_image_gt(dataset, config, image_idx, use_mini_mask=False)\n",
    "    \n",
    "        # Prediction\n",
    "        print(\"Start prediction\", subimage)\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        if len(r['class_ids']) == 0: #no instance detected\n",
    "            full_mask_maskrcnn = np.zeros((1024,1024))\n",
    "        else:\n",
    "            mask_rcnn = r[\"masks\"]\n",
    "            full_mask_maskrcnn = np.sum(mask_rcnn,2)\n",
    "            full_mask_maskrcnn = np.where(full_mask_maskrcnn<2,full_mask_maskrcnn,1)\n",
    "        \n",
    "        (subimx,subimy) = subimage\n",
    "        if subimx<4 and subimy<4:\n",
    "            mask_maskrcnn_concatenate[subimy*1024:(subimy+1)*1024, subimx*1024:(subimx+1)*1024]=full_mask_maskrcnn\n",
    "        \n",
    "        elif subimx==4 and subimy!=4:\n",
    "            mask_maskrcnn_concatenate[subimy*1024:(subimy+1)*1024, 3976:5000]=full_mask_maskrcnn\n",
    "            \n",
    "        elif subimy==4 and subimx!=4:\n",
    "            mask_maskrcnn_concatenate[3976:5000, subimx*1024:(subimx+1)*1024]=full_mask_maskrcnn\n",
    "            \n",
    "        elif subimy==4 and subimx==4:\n",
    "            mask_maskrcnn_concatenate[3976:5000, 3976:5000]=full_mask_maskrcnn\n",
    "            \n",
    "    mask_maskrcnn_concatenate = mask_maskrcnn_concatenate.astype(np.uint8)\n",
    "            \n",
    "        \n",
    "    print(\"Image saved !\")\n",
    "    out = Image.fromarray((mask_maskrcnn_concatenate*255).astype(np.uint8))\n",
    "    out.save(PREDICTIONS_DIR+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(self.mask_dir, name)*((subset==\"train\")|(subset==\"val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:objreco_namr]",
   "language": "python",
   "name": "conda-env-objreco_namr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
