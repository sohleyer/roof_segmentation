{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Training Model\n",
    "\n",
    "<i> SÃ©bastien Ohleyer </i>\n",
    "\n",
    "Training notebook.\n",
    "\n",
    "Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline\n",
    "ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import aerial\n",
    "config = aerial.AerialConfig()\n",
    "\n",
    "# Local\n",
    "AERIAL_DIR = \"/Users/sebastienohleyer/Documents/ENS MVA/Object recognition/AerialImageDataset/\"  # TODO: enter value here\n",
    "COCO_MODEL_PATH = \"~/Document/ENS MVA/Object recognition/Mask_RCNN-coco/coco_weigths/mask_rcnn_coco.h5\"\n",
    "MODEL_DIR = \"../trained_model/\"\n",
    "\n",
    "# Floydhub\n",
    "#AERIAL_DIR = \"/\"\n",
    "#COCO_MODEL_PATH = \"/coco_weights/mask_rcnn_aerial_0035.h5\"\n",
    "#MODEL_DIR = \"/output/trained_model/\"\n",
    "# run : floyd run --data sohleyer/datasets/aerialimagedataset_train/1:/train --data sohleyer/datasets/coco_weights/1:/coco_weights --env tensorflow-1.3 --mode jupyter\n",
    "\n",
    "# AWS\n",
    "#AERIAL_DIR = \"/home/ubuntu/aerialimagedataset\" \n",
    "#COCO_MODEL_PATH = \"/home/ubuntu/mask_rcnn/trained_model/<NAME>\"\n",
    "#MODEL_DIR = \"/home/ubuntu/mask_rcnn/output/\"\n",
    "# run : floyd run --data sohleyer/datasets/aerialimagedataset_train/1:/train --data sohleyer/datasets/coco_weights/1:/coco_weights --env tensorflow-1.3 --mode jupyter\n",
    "\n",
    "TOWN_LIST = [\"austin\", \"chicago\", \"kitsap\", \"tyrol-w\", \"vienna\"]\n",
    "IMAGE_PER_TOWN = None\n",
    "SUBIMAGE_LIST = [(0,1),(1,1),(2,1),(3,1),(4,1)]\n",
    "\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset train\n",
    "dataset_train = aerial.AerialDataset()\n",
    "dataset_train.load_aerial(dataset_dir=AERIAL_DIR, subset=\"train\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST, image_per_town=IMAGE_PER_TOWN)\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset_train.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[dataset_train.image_info[i][\"image_name\"] for i in dataset_train.image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset val\n",
    "dataset_val = aerial.AerialDataset()\n",
    "dataset_val.load_aerial(dataset_dir=AERIAL_DIR, subset=\"val\", subimage_list=SUBIMAGE_LIST, town_list=TOWN_LIST, image_per_town=IMAGE_PER_TOWN)\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
    "print(\"Class Info: {}\".format(dataset_val.class_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[dataset_val.image_info[i][\"image_name\"] for i in dataset_val.image_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 : Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=20, layers='4+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stage 3 : Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE / 10, epochs=40, layers=\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:objreco_namr]",
   "language": "python",
   "name": "conda-env-objreco_namr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
